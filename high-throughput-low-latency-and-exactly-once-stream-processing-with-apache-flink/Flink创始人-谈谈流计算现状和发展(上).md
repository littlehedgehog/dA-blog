> 本文主要翻译自[《high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink》](https://data-artisans.com/blog/high-throughput-low-latency-and-exactly-once-stream-processing-with-apache-flink)，作为Flink发明人以及dA CEO，Kostas Tzoumas对于流式处理有深入的见解。文章分为两部分，本篇文章是上半部分有关流式计算核心能力的介绍和探讨。文章考虑到语言文化差异，对于部分较难理解部分加入我自己的说明。


# 前言

当前，流数据平台的普及率正在飙升。为了解决日益增长的实时数据处理需求，一些公司正在将其部分的大数据基础架构转换为流式处理模型。 基于流数据的基础架构不仅能够更好地解决一些延迟敏感的数据处理业务需求，同时提供更多深入业务洞察; 另外，流式数据处理平台让传统的数据仓库的建设更加简单灵活。

流式基础架构的关键部分是流计算引擎。优秀的流式计算引擎可以让业务即使在有状态计算的情况下，也能提供低延迟、高吞吐、强一致性。在之前的文章中，我们介绍了Apache Flink™作为可扩展的流处理引擎，它提供了这种属性的组合。

在本文中，我们将深入探讨Flink的检查点机制如何工作，以及它如何取代旧架构以实现流容错和恢复。 我们测量Flink在各种类型的流媒体应用程序中的性能，并通过在Apache Storm（一种广泛使用的低延迟流处理器）上运行相同系列的实验来进行效果对比。


# 流式处理架构演化

在流式计算领域，同一套系统需要同时兼具容错和高性能其实非常难。 在传统的批处理中，当作业失败时，可以简单地重新运行作业的失败部分以修复由于之前失败导致的数据丢失。 这对于批处理是完全可行的，因为批处理的数据是静态的，可以从头到尾重放。 在连续的流式处理模型中，这种处理思路是完全不可行的。 原则上，数据流是无穷无尽的，不具有开始点和结束点。 一个带有Buffer缓存的数据流或许可以进行一小段的数据重放、重新计算(即: 如果系统出错，系统可以尝试从在Buffer中缓存的数据流进行重新计算)，但出错时希望从数据流最开始点进行重新计算是不切实际的（例如，一个流作业可以运行数月之久，当出现系统故障时候导致数据计算出错不可能参考批处理系统，从几个月前的数据开始计算）。 此外，与仅具有输入和输出的批处理作业相比，流式计算是有状态的。 这意味着除了输出之外，系统还需要备份和恢复部分计算(我们称之为Operator，下同)状态。 由于这些问题带来的诸多复杂性，开源生态系统多个系统都在尝试多种方式来解决容错问题。容错机制的设计将对框架设计预计编程模型都有深远的影响，导致难以在现有的流式框架上类似插件机制一样扩展实现不一样的容错策略。因此，当我们选择流式计算内框架时，容错策略非常重要。


接下来，我们将讨论了容错流式架构的几种方法，从记录确认(record-acknowledgements)到微批处理(micro-batching)，事务更新（transactional updates）和分布式快照（distributed snapshots）。 我们将从以下几个维度讨论各个系统的优缺点，同时最终选出一个适合流式处理的最优Feature组合。 我们将讨论：

* 完全一次保证：故障后应正确恢复有状态运算符中的状态
* 低延迟：越低越好。 许多应用程序需要亚秒级延迟
* 高吞吐量：随着数据速率的增长，通过管道推送大量数据至关重要
* 强大的计算模型：框架应该提供一种编程模型，该模型不限制用户并允许各种各样的应用程序
* 在没有故障的情况下，容错机制的开销很低
* 流量控制：来自慢速操作员的背压应该由系统和数据源自然吸收，以避免因消费者缓慢而导致崩溃或降低性能

我们遗漏了一个共同特征，即失败后的快速恢复，不是因为它不重要，而是因为（1）所有讨论的系统都是基于完全并行的分布式处理系统，恢复是基础能力；以及（2）在有状态的应用程序中，状态恢复的瓶颈通常在于存储而非计算框架。


# Record acknowledgements  (记录确认，代表系统Apache Storm)

虽然流处理已经在诸如金融等行业中广泛使用多年，但直到最近流式处理才能为大数据的基础设施的一部分。 这些都得益于开源的流式大数据处理引擎成熟和发展。 Apache Storm是开源生态中第一个广泛使用的大规模流处理框架。 Storm使用[上游备份机制和记录确认机制](https://storm.apache.org/documentation/Guaranteeing-message-processing.html)来保证在失败后重新处理消息。 请注意，Storm不保证状态一致性，任何可变状态处理都委托给用户来处理（Storm的Trident API确保状态一致性，将在下一节中介绍）。

> 译者注: 以下内容理解需要读者一定的Apache Storm基础，请参看Apache Storm [官方文档](https://storm.apache.org/releases/1.2.2/Concepts.html)有关Storm关键概念的描述。

记录确认的容错方式如下：当前Operator处理完成每条记录时都会向前一个Operator发回针对这条记录**处理过的确认**。 Topology的Source(译者注: Storm的Source节点指Storm一个作业中负责从流式源头读取数据的Operator)会保留其产生的所有记录备份用来处理Fail情况。 当源头一条记录的所有派生记录都被整个Topology处理完成，Source节点就可以删除其备份；当系统出现部分Fail情况，例如一条记录并没有收到其下游的派生记录的确认，Source就会重新发送该记录到下游的Topology以便重新进行计算。 这种处理机制可以保证整个处理过程不会丢失数据，但很有可能导致同一条记录被多次发送到下游进行处理（我们称之为“at least once”）。 Storm使用一种巧妙的机制来实现这种容错方式，每个源记录只需要几个字节的存储来跟踪确认。 Twitter Heron保持与Storm相同的确认机制，但提高了记录重放的效率（从而提高了恢复时间和整体吞吐量）。

单独的记录确认容错体系结构，无论其性能如何，都无法提供exactly-once(精确一次)的保证，Storm将规避重复数据的问题交给了流式处理应用开发者去处理。 当然，对于某些应用程序而言，数据小部分重复可以接受的，但仍然有更多的场景无法接受数据不准确的情况。另外，Storm的容错机制还带来了吞吐不够以及流控问题， 特别是在backpressure(反压)情况下，记录确认的容错方式会导致上游节点错误地认为数据处理出现了Fail(实际上仅仅是由于backpressure导致记录处理不及时，而无法ack)。上述Storm的种种问题最终演化出基于微批处理的流式架构。


# Micro batches（微批处理，代表系统 Apache Storm Trident，Apache Spark Streaming）

上节讨论到，Storm和以及更早前的流式传输系统无法提供对大规模应用程序至关重要的一些Feature，特别是高吞吐量，快速并行恢复，以及托管状态的一次性语义。 这导致了下一阶段的流式系统演化。

之后，具备容错能力的下一个发展阶段到了微批处理，或者说流离散化(stream discretization，即将连续的流切分为一个个离散的、小批次的微批进行处理)。这个出发点非常简单：流式处理系统中的算子都是在record级别进行计算同步和容错，由此带来了在record如此低层次上进行处理的复杂和开销。很简单嘛，我们就把连续的数据流不要切分到record级别，而是收敛切分为一批一批微批的、原子的数据进行类似Batch的计算。这样，每个batch的数据可能会成功或者失败处理，我们就对当前失败的这一小批数据进行处理即可。

![图片](https://data-artisans.com/wp-content/uploads/2015/08/microbatching-1024x651.png)

微批处理本质上一种批处理模型，显然可以利用现有的批处理引擎就可以完成流式计算。例如，可以在批处理引擎（Spark）提供流功能（这是Spark Streaming背后的基本机制），当前它也可以应用于流引擎之上（例如， Storm）提供一次性保证和状态恢复（这是Storm Trident背后的想法）。 在Spark Streaming中，每次的微批量计算都是一个Spark作业，而在Trident中，每个微批次都是一个大型记录，微批次中的所有记录都会合并进入一个大型记录。

基于微批处理的系统可以实现上面列出的相当多的需求（确切一次保证，高吞吐量），但它们还有很多不足之处：

* 编程模型：为了实现其目标，例如，Spark Streaming将编程模型从流式更改为微批处理。 这意味着用户不能再在检查点间隔的倍数之外的时段中窗口数据，并且模型不能支持许多应用程序所需的基于计数或会话窗口。 这些都是应用程序开发人员需要的需求。具有可以改变状态的连续运算符的纯流模型为用户提供了更大的灵活性。

* 流量控制：使用基于时间的数据切分为微批的处理方式仍然具有backpressure固有问题。 如果某个下游的Operator处理较慢（例如，计算密集型Operator处理性能跟不上或者向外部存储写出数据较慢），此时如果负责数据流切分的Operator速度快于下游的阻塞节点，就会导致数据切分比原有的配置时间更长。 这导致越来越多的批次在内存排队等待被处理，最终内存OOM，或者微批的时间间隔增大导致数据不精确。

* 延迟：微批处理显然加大了流计算延迟，一个微批作业的延迟最好情况也只能到微批的间隔时间。 通常情况下，亚秒级别的延迟对于一些简单应用程序足够，但一个较为复杂的流式处理任务，例如单个作业内部存在多个阶段，每个阶段存在大量分布式数据shuffle情况，很容易将整个作业延迟拉长的数秒甚至数十秒。

微批处理模型的最大限制可能是它连接了两个不应连接的概念：应用程序定义的窗口大小和系统内部恢复间隔。 假设一个程序（下面是示例Flink代码）每5秒聚合一次记录：

```
dataStream
.map(transformRecords)
.groupBy(“sessionId”)
.window(Time.of(5, TimeUnit.SECONDS))
.sum(“price”)
```

这些应用非常适合微批量模型。 系统累积5秒的数据，对它们求和，并在对流进行一些转换后聚合计算。 下游数据应用程序可以直接使用上述5秒聚合的结果进行数据消费，例如在仪表板上显示。 但是，现在假设backpressure效应开始起作用（例如，由于计算密集型的transformRecords函数），或者devops团队决定通过将间隔增加到10秒来控制作业的吞吐量。 然后，在出现backpressure情况下，微批量大小不受控制地动态进行改变，或者直接变为10秒。 这意味着下游应用程序（例如，包含最近5秒统计的Web仪表板）读取的聚合数据是错误的，下游应用程序需要自己处理此问题。 这样，流计算系统由于性能或者吞吐问题，直接导致了运行数据错误。

微批处理可以实现高吞吐量和一次性保证，但这些功能室以丧失低延迟，流量控制和纯流式编程模型为代价滴。 显然，我们需要思考清楚的是，是否有可能实现两全其美：在保持持续计算(continuous process)的运算符模型的所有优势，同时兼备一致性、高吞吐量等优势。 后面讨论的后续流式架构实现了这种Feature的组合，并将微批处理作为流式处理的基本模型。

注意：通常微批处理被认为是一次处理一条记录的替代方法。 这是见文生义的做法：**所谓的连续计算并不是连续地一次处理一条记录**。 实际上，**所有精心设计的流计算系统（包括下面讨论的Flink和Google Dataflow）在通过网络传输之前会缓冲许多记录，同时又具备流式连续处理能力**。


# Transactional updates (代表系统 Google Cloud Dataflow)

如何做到鱼和熊掌兼得？在保持连续计算模型（低延迟，反压流控，状态管理等）的好处，同时保证做到数据处理的准确一致。一种强大而不失优雅的方式是原子地记录数据的处理以及状态的更新(译者注: 类似数据的WAL日志)。 一旦系统出现Fail，可从记录的日志中恢复我们需要的中间计算状态和需要处理数据。

在Google Cloud Dataflow中实现类似的模型。 系统将计算模型抽象为一次部署并长期运行持续计算的Operator DAG。 在Dataflow中，数据的shuffle是流式的而非批模式，同时计算结果亦不需要物化(数据的计算结果放在内存中)。 这种模型不仅解决了流式计算低延迟问题，同时还天然支持自然流量控制机制，因为DAG不同阶段的Operator之间存有中间结果的Buffer，这些中间缓冲区可以缓解反压，直到反压恶化到最源头的Operator，即DataFlow Source节点。而基于Pull模型的流式数据源，如Kafka消费者可以处理这个问题，即Source节点的中间结果Buffer会出现积压导致读取Kafka变慢，但不会影响上游的流数据采集。 系统还支持一套干净的流编程模型，支持复杂的窗口，同时还提供对状态的更新操作。 值得一提的是，这套流编程模型包含微批量模型。

例如，下面Google Cloud Dataflow程序（请参阅[此处](https://cloud.google.com/dataflow/model/windowing) ）会创建一个会话窗口，如果针对某个Key在10分钟内都没有数据达到，则会触发该会话窗口(译者注: 例如某个用户在访问APP期间中断了10分钟没有操作)。 而间隔10分钟后，如果新的数据到达，系统将创建一个新的会话窗口。

```
PCollection<String> items = ...;
PCollection<String> session_windowed_items = items.apply(
    Window.<String>into(Sessions.withGapDuration(Duration.standardMinutes(10))))
```

这种数据的处理方式在流式模型中很容易实现，但在微批量模型中很难实现，因为数据窗口的定义不对应于固定的微批量大小。

这种架构中的容错设计如下：通过Operator的每个中间记录，和本Operator计算带来的状态更新，以及有本条记录派生的新记录，一起做一次原子事务并提交到事务性日志系统或者数据库系统。
在系统出现失败的情况下，之前数据库的记录将被重放，用于恢复计算的中间状态，同时将丢失没有来得及计算的数据重新读取进行计算。

Apache Samza遵循类似的方法，但只能提供at-least-once保证 ，因为它使用Apache Kafka作为后台存储。 Kafka（现在）不提供事务，因此对状态和派生流记录的更新不能作为原子事务一起提交。

事务更新体系结构具有许多优点。 事实上，它实现了我们在本文开头提出的所有需求。 该体系结构的基础是能够频繁地写入具有高吞吐量的分布式容错存储。 分布式快照（在下一节中进行了解释）将拓扑的状态作为一个整体进行快照，从而减少了对分布式存储的写入量和频率。

# Distributed Snapshots (代表系统 Apache Flink™)
提供exactly-once流式处理语义保证的核心问题就是 **确定当前流式计算的状态(包括正在处理的数据，以及Operator状态)，生成该状态的一致快照，并存储在持久存储中**。如果可以经常执行状态保存的操作，则从故障恢复意味着仅从持久存储中恢复最新快照，将源头Source回退到快照生成时刻再次进行”播放”。Flink的状态算法在[这篇论文](http://arxiv.org/abs/1506.08603)有详细说明，以下我们给出一个简单总结。

Flink的快照机制基于Chandy和Lamport于1985年设计的算法，用于生成分布式系统当前状态的一致快照（请参阅此处的[详细介绍](https://blog.acolyer.org/2015/04/22/distributed-snapshots-determining-global-states-of-distributed-systems/) ），不会丢失信息且不记录重复项。 Flink使用的是Chandy Lamport算法的一个变种，定期对正在运行的流拓扑的状态做快照，并将这些快照存储到持久存储（例如，存储到HDFS或内存中文件系统）。 这些做快照的频率是可配置的。

这类似于微批处理方法，其中两个检查点之间的所有计算都作为一个整体原子地成功或失败。 然而，这个就是两者唯一的类似点。 Chandy Lamport算法的一个重要特点是我们永远不必按流处理中的“暂停”按钮，用来等待检查点完成后安排下一次Batch数据处理。 相反，常规数据处理始终保持运行，而状态持久化仅在后台发生。 以下引用原始论文，

> 全局状态检测算法应该被设计在基础(业务)计算之上：它必须与此基础(业务)计算同时并行进行，但不能侵入改变基础(业务)计算。

因此，该架构结合了遵循真正的持续计算模型（低延迟，流量控制和真正的流编程模型）和高吞吐量的优点，并且也是Chandy-Lamport算法可证明的一次性保证。 除了持久化有状态计算的状态（每个其他容错机制也需要这样做）之外，这种容错机制几乎没有开销。 对于小状态（例如，计数或其他统计摘要），这种持久化开销通常可忽略不计，而对于大状态，状态持久化间隔需要流计算应用开发者在吞吐量和恢复时间之间进行权衡。

最重要的是，该架构将应用程序开发与流量控制、吞吐量控制分开。 更改快照持久化的间隔时间对流作业的结果完全没有影响，因此下游应用程序可以安全地依赖于接收正确的结果。

Flink的检查点机制基于stream barriers（可以理解为​​Chandy Lamport中的“标记”），这些barrier像正常的业务数据一样在Operator和Operator之间的数据管道中流动。 Flink的检查点的描述来自于[Flink社区文档](https://ci.apache.org/projects/flink/flink-docs-master/internals/stream_checkpointing.html) ) 。

Barrier在Source节点中被注入到普通流数据中（例如，如果使用Apache Kafka作为源，Barrier将与Kafka的读取偏移对齐），并且作为数据流的一部分与数据记录一起流过下游的DAG。 Barrier将业务数据流分为两组：当前快照的一部分（Barrier表示检查点的开始），以及属于下一个快照的那些组。

![Flink Checkpoint](https://data-artisans.com/wp-content/uploads/2015/08/streambarrier.png)

Barrier流向下游并在通过Operator时触发状态快照。 Operator首先将Barrier与所有传入的流分区（通常Barrier具有多个输入）对齐，上游来源较快的流分区将被缓冲数据以等待来源较慢的流分区。 当Operator从每个输入流分区都收到Barrier时，它会检查其状态（如果有）并写入持久存储，这个过程我们称之为**状态写检查**。一旦完成状态检查点，Operator就将Barrier向下游转发。 请注意，在此机制中，如果Operator支持，则状态检查点既可以是异步（在写入状态时继续处理），也可以是增量（仅写入更改）。

![Flink Barrier](https://data-artisans.com/wp-content/uploads/2015/08/operatorcheckpoints-1024x427.png)

一旦所有数据写出端(即Flink Sink节点)都收到Barrier，当前检查点就完成了。 故障恢复意味着只需恢复最新的检查点状态，并从最新的Barrier记录的偏移量重新启动Source节点。 分布式快照在我们在本文开头所要达到的所有需求中得分很高。 它们实现了高吞吐量、一次性保证，同时保留了连续的Operator模型、低延迟以及自然流量控制。

# 总览
我们从这篇文章开始，列出了来自分布式流体系结构的需求。下表总结了我们讨论的每个体系结构如何支持这些功能。

|item|Record ACK|Micro-batching|Transactional updates|Distributed snapshots|
|:---|:----|:----|:---|:----|
|语义保证|At least once|Exactly once|Exactly once|Exactly once|
|延迟|低|高|较低(事务延迟)|低|
|吞吐|低|高|较高(取决于做事务存储吞吐)|高|
|计算模型|流|微批|流|流|
|容错开销|高|低|较低(取决于事务存储的吞吐)|低|
|流控|较差|较差|好|好|
|业务灵活性(业务和容错分离)|部分|紧耦合|分离|分离|
